{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEXhU0pV3OPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGTgAdx6ZR6",
        "colab_type": "text"
      },
      "source": [
        "**Initializing Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM2N593t3f60",
        "colab_type": "code",
        "outputId": "0bc64f8f-4336-4f3d-c439-3dddc36d4521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x = torch.ones(3, 2)\n",
        "print(x)\n",
        "x = torch.zeros(3, 2)\n",
        "print(x)\n",
        "x = torch.rand(3, 2)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.0917, 0.6097],\n",
            "        [0.6679, 0.2763],\n",
            "        [0.5771, 0.3333]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoTzkjxG6vSS",
        "colab_type": "code",
        "outputId": "75691fcf-52e4-4641-ae7e-88d6a51f1e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x = torch.empty(3, 2) ## creating tensor but not initializing it, initial values will be values stores at the address\n",
        "print(x)\n",
        "y = torch.zeros_like(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.1526e-36, 0.0000e+00],\n",
            "        [4.4842e-44, 0.0000e+00],\n",
            "        [       nan, 4.2320e+21]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4r0bXut66qz",
        "colab_type": "code",
        "outputId": "2c6a2e2e-c63c-4bf6-80c2-c5232ef31c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.linspace(0, 1, steps=5)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fR27sFc7EGx",
        "colab_type": "code",
        "outputId": "4611ee24-9c5e-4943-8f42-a3eb512d5438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.tensor([[1, 2],\n",
        "                  [3, 4],\n",
        "                  [5, 6]])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPPJDa8Z7Pgk",
        "colab_type": "text"
      },
      "source": [
        "**Slicing Tensor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52YRUhDN7LRG",
        "colab_type": "code",
        "outputId": "24f3aefb-2999-4b93-8d5b-264ce14e1caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.size())\n",
        "print(x[:, 1])\n",
        "print(x[0,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4uCabFv7SxO",
        "colab_type": "code",
        "outputId": "aba07c8a-74a2-44f3-abbb-cbc25e933fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = x[1, 1]\n",
        "print(y)\n",
        "print(y.item()) # change tensor to numeric value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNgDVPPh70ZV",
        "colab_type": "text"
      },
      "source": [
        "**Reshaping Tensor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4fQal2f7hhm",
        "colab_type": "code",
        "outputId": "e6b15a80-799e-45db-accf-90b4c0fd3936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(x)\n",
        "y = x.view(2, 3)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLeKndw8K7l",
        "colab_type": "code",
        "outputId": "a1d85126-b9b9-4503-bf43-77ec1b2a23ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y = x.reshape(6, -1)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNYjmf6-8-4w",
        "colab_type": "text"
      },
      "source": [
        "**Simple Tensor Operation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IsNXk7A8V8o",
        "colab_type": "code",
        "outputId": "508406e3-003d-42f3-9c3b-9f7f42339d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x = torch.ones(3, 2)\n",
        "y = torch.ones(3, 2)\n",
        "x[2,1] = 0\n",
        "z = x + y\n",
        "print(z)\n",
        "z = x - y\n",
        "print(z)\n",
        "z = x * y\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 1.]])\n",
            "tensor([[ 0.,  0.],\n",
            "        [ 0.,  0.],\n",
            "        [ 0., -1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l9QjWsU9Oe8",
        "colab_type": "code",
        "outputId": "20d2a42f-cd03-4a32-b417-a3ccb977e4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "z = y.add(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDK0HPyO9dV7",
        "colab_type": "code",
        "outputId": "3ee83346-05d9-41de-c325-8058d974e5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "z = y.add_(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 1.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ps9Uwb9jRT",
        "colab_type": "code",
        "outputId": "df7149e0-62ab-4926-c186-22958b0bfd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "a = torch.tensor([5, 6])\n",
        "z = y.add(a)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7., 8.],\n",
            "        [7., 8.],\n",
            "        [7., 7.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wmo8oww-uh_",
        "colab_type": "text"
      },
      "source": [
        "**Numpy <-> Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGcj5l7Z9lDM",
        "colab_type": "code",
        "outputId": "87622512-8781-459f-bb30-168b0e3bf739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "x_np = x.numpy() ## bridge between numpy tensor value and if you update 1 other one is also affected\n",
        "print(x_np)\n",
        "print(type(x_np), type(x))\n",
        "x.add_(1)\n",
        "print(x_np)\n",
        "print(x) \n",
        "x += 1\n",
        "print(x_np)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 2.]\n",
            " [2. 2.]\n",
            " [2. 1.]]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
            "[[3. 3.]\n",
            " [3. 3.]\n",
            " [3. 2.]]\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.],\n",
            "        [3., 2.]])\n",
            "[[4. 4.]\n",
            " [4. 4.]\n",
            " [4. 3.]]\n",
            "tensor([[4., 4.],\n",
            "        [4., 4.],\n",
            "        [4., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yebPGi_y-40x",
        "colab_type": "code",
        "outputId": "92d98a5d-2a21-488f-f5ee-ec269c2ac132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "a = np.random.randn(5)\n",
        "a_tr = torch.from_numpy(a)\n",
        "print(type(a), type(a_tr))\n",
        "print(a_tr)\n",
        "print(a)\n",
        "a_tr.add_(1)\n",
        "print(a_tr)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
            "tensor([-0.4314, -0.1954,  0.7062, -0.5024,  0.0379], dtype=torch.float64)\n",
            "[-0.43142351 -0.19541321  0.70618475 -0.50238696  0.03787427]\n",
            "tensor([0.5686, 0.8046, 1.7062, 0.4976, 1.0379], dtype=torch.float64)\n",
            "[0.56857649 0.80458679 1.70618475 0.49761304 1.03787427]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ScwmLj-_m6t",
        "colab_type": "code",
        "outputId": "5467a721-fbb2-48a7-d4db-a5e95802b484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = np.random.randn(100, 100)\n",
        "  b = np.random.randn(100, 100)\n",
        "  # c = a * b\n",
        "  c = np.matmul(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 154 ms, sys: 114 ms, total: 268 ms\n",
            "Wall time: 150 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2McZfvG9_5pE",
        "colab_type": "code",
        "outputId": "bfe4ebdd-ef2d-40b7-a898-6c2fc8ddf2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = torch.randn(100, 100)\n",
        "  b = torch.randn(100, 100)\n",
        "  # c = a * b\n",
        "  c = torch.matmul(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.9 ms, sys: 1.86 ms, total: 26.8 ms\n",
            "Wall time: 80.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzzVeB6oAGgP",
        "colab_type": "code",
        "outputId": "d179d7cd-deb4-4425-bb26-541a495e0f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000, 10000)\n",
        "  b = np.random.randn(10000, 10000)\n",
        "  c = a + b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 35s, sys: 1.28 s, total: 1min 36s\n",
            "Wall time: 1min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acFfF6kCArtu",
        "colab_type": "code",
        "outputId": "1c6cb4cf-ab47-43f3-b003-0227ef1d8753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn(10000, 10000)\n",
        "  b = torch.randn(10000, 10000)\n",
        "  c = a + b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16 s, sys: 5.92 ms, total: 16 s\n",
            "Wall time: 16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq71BLtYBSMK",
        "colab_type": "text"
      },
      "source": [
        "**CUDA Support**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5m-onOuBEa4",
        "colab_type": "code",
        "outputId": "87999cfc-d61f-426f-9517-691ff3ea6b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jKEXY6rB8Wr",
        "colab_type": "code",
        "outputId": "8126bb77-caaf-40da-8965-c19018088c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x7f686bc939e8>\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99lWC47ECVSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVO3DvPGCiKV",
        "colab_type": "code",
        "outputId": "5117621b-a7a2-4162-8e23-20b06abefd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "a = torch.ones(3, 2, device=cuda0)\n",
        "b = torch.ones(3, 2, device=cuda0)\n",
        "c = a + b\n",
        "print(c)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0mqHfuhCwQZ",
        "colab_type": "code",
        "outputId": "7b8cb702-ed85-41e4-b3e6-006e8a1a132f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000, 10000)\n",
        "  b = np.random.randn(10000, 10000)\n",
        "  np.add(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 26s, sys: 563 ms, total: 1min 27s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80z4q_cKDJmL",
        "colab_type": "code",
        "outputId": "515e91c4-68f0-455d-bea3-6f4671d4368c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn(10000, 10000)\n",
        "  b = torch.randn(10000, 10000)\n",
        "  b.add_(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.5 s, sys: 7.75 ms, total: 17.5 s\n",
            "Wall time: 17.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJgTVLAmDSXR",
        "colab_type": "code",
        "outputId": "7f923035-221a-4b32-edcf-028fa25fc39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn(10000, 10000, device=cuda0)\n",
        "  b = torch.randn(10000, 10000, device=cuda0)\n",
        "  b.add_(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.4 ms, sys: 3.99 ms, total: 6.39 ms\n",
            "Wall time: 11.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg-LDy5KDb5H",
        "colab_type": "code",
        "outputId": "f12c7b13-e866-43b3-f9ef-5968ea9a8577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000, 10000)\n",
        "  b = np.random.randn(10000, 10000)\n",
        "  np.matmul(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 29s, sys: 3.18 s, total: 20min 32s\n",
            "Wall time: 11min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io3Ga6X3Du1Y",
        "colab_type": "code",
        "outputId": "d5cc16df-303d-4990-9f85-d72a44d4f044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn(10000, 10000)\n",
        "  b = torch.randn(10000, 10000)\n",
        "  torch.matmul(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 49s, sys: 195 ms, total: 4min 49s\n",
            "Wall time: 4min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d3HwtFnD0hZ",
        "colab_type": "code",
        "outputId": "4880e748-8a2e-4964-cc63-07c9e8ac66a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn(10000, 10000, device=cuda0)\n",
        "  b = torch.randn(10000, 10000, device=cuda0)\n",
        "  torch.matmul(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.28 ms, sys: 8.01 ms, total: 17.3 ms\n",
            "Wall time: 17.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-yZHI3oEOg3",
        "colab_type": "text"
      },
      "source": [
        "**Autograd**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VoKp6EqD7_n",
        "colab_type": "code",
        "outputId": "e82271fd-329d-4601-f4e2-8d9c7ba41835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD2oZljqFVZc",
        "colab_type": "code",
        "outputId": "9dcc31a2-0807-499f-8635-fff18ac8c571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = x + 5\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYohEu-gFXGW",
        "colab_type": "code",
        "outputId": "a4171c07-b924-4f03-f758-6518a8f24021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z = y * y + 1\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYSe4BjIFZDv",
        "colab_type": "code",
        "outputId": "bef7ead5-0b56-43a5-f276-bc45b2f782e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = torch.sum(z)\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Bcr45cFb_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUUFnZiPFgkN",
        "colab_type": "code",
        "outputId": "c8e022a7-08eb-4574-d75e-24e0e58c69b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZsVrVQiFora",
        "colab_type": "code",
        "outputId": "a19196c0-bb7a-48ae-89cb-be01f6cdeaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1 / (1 + torch.exp(-y))\n",
        "print(r)\n",
        "s = torch.sum(r)\n",
        "s.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbBm70J8JABM",
        "colab_type": "code",
        "outputId": "14d3fee1-fbe4-457b-c8c9-3b29f9b8db3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1/(1 + torch.exp(-y))\n",
        "a = torch.ones([3, 2])\n",
        "r.backward(a)\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whz7tBGlKto1",
        "colab_type": "text"
      },
      "source": [
        "**Autograd example for what we have been doing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZUgwdaBKiJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn([20, 1], requires_grad=True)\n",
        "y = 3*x - 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjJR6-yvL9xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "y_hat = w*x + b\n",
        "\n",
        "loss = torch.sum((y_hat - y)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcYewGb1MNYB",
        "colab_type": "code",
        "outputId": "a06a20a9-b545-4d13-f321-20d7f3d084a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(173.3331, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZD7GWvDMO_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WKwhnaMQP2",
        "colab_type": "code",
        "outputId": "c4e01041-50bf-4323-e69f-90af1932a499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(w.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-31.8708]) tensor([94.3082])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIQudB8JMU9d",
        "colab_type": "text"
      },
      "source": [
        "**Do it in a loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZQ3kzsUMR_R",
        "colab_type": "code",
        "outputId": "c8402362-cbf9-4898-b22d-6d9a9634db35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "print(w.item(), b.item())\n",
        "for i in range(10):\n",
        "  x = torch.randn([20, 1])\n",
        "  y = 3*x - 2\n",
        "\n",
        "  y_hat = w*x + b\n",
        "\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  print(loss)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad(): ## we use no grad to make sure weight update equations are not part of computation graph generated for forward prop\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(w.item(), b.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 1.0\n",
            "tensor(264.2288, grad_fn=<SumBackward0>)\n",
            "1.788204312324524 -0.23605561256408691\n",
            "tensor(112.2058, grad_fn=<SumBackward0>)\n",
            "2.474776268005371 -1.0366086959838867\n",
            "tensor(32.0036, grad_fn=<SumBackward0>)\n",
            "2.847053050994873 -1.4980437755584717\n",
            "tensor(5.8267, grad_fn=<SumBackward0>)\n",
            "2.932461738586426 -1.7041802406311035\n",
            "tensor(1.9337, grad_fn=<SumBackward0>)\n",
            "2.9753899574279785 -1.82511305809021\n",
            "tensor(0.6169, grad_fn=<SumBackward0>)\n",
            "2.9805140495300293 -1.894938588142395\n",
            "tensor(0.2372, grad_fn=<SumBackward0>)\n",
            "2.9948835372924805 -1.9374244213104248\n",
            "tensor(0.0771, grad_fn=<SumBackward0>)\n",
            "2.993621587753296 -1.9621846675872803\n",
            "tensor(0.0285, grad_fn=<SumBackward0>)\n",
            "2.9947292804718018 -1.9770946502685547\n",
            "tensor(0.0099, grad_fn=<SumBackward0>)\n",
            "2.994443893432617 -1.9857807159423828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwdvyErgOgtg",
        "colab_type": "text"
      },
      "source": [
        "**Do it for large value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qMOFE_N8jF",
        "colab_type": "code",
        "outputId": "198ab1aa-568a-4817-9321-4a2a790a4164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "learning_rate = 0.01\n",
        "N = 1000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True)\n",
        "b = torch.ones([1], requires_grad=True)\n",
        "\n",
        "print(torch.mean(w).item(), b.item())\n",
        "\n",
        "for i in range(epochs):\n",
        "  x = torch.randn([N])\n",
        "  y = torch.dot(3*torch.ones([N]), x) - 2\n",
        "\n",
        "  y_hat = torch.dot(w, x) + b\n",
        "\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  # print(loss)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(torch.mean(w).item(), b.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5238341093063354 1.0\n",
            "0.5254179239273071 0.479810893535614\n",
            "0.5614647269248962 1.9451277256011963\n",
            "0.5345283150672913 3.800072431564331\n",
            "0.5922037363052368 1.9026570320129395\n",
            "0.5779885053634644 0.43874454498291016\n",
            "0.6663611531257629 -3.1575396060943604\n",
            "0.6707050800323486 -5.5738067626953125\n",
            "0.6881402134895325 -4.782465934753418\n",
            "0.5840356945991516 -0.6204061508178711\n",
            "0.549179196357727 0.2868614196777344\n",
            "0.632590651512146 2.80442476272583\n",
            "0.8605751991271973 -7.764693737030029\n",
            "1.4470272064208984 -17.75151824951172\n",
            "0.6740983724594116 -1.9394607543945312\n",
            "0.5829266309738159 -6.386473178863525\n",
            "0.6323782205581665 -18.88169288635254\n",
            "0.41367223858833313 -46.89295959472656\n",
            "0.4325815439224243 -31.50178337097168\n",
            "-0.013324722647666931 -9.17243766784668\n",
            "0.6443884968757629 25.098642349243164\n",
            "0.8476313352584839 33.65824890136719\n",
            "1.4431465864181519 24.003257751464844\n",
            "1.2425061464309692 12.566157341003418\n",
            "1.0707595348358154 14.85265827178955\n",
            "0.9679262638092041 5.286731719970703\n",
            "1.4159374237060547 33.708763122558594\n",
            "1.9765703678131104 5.189035415649414\n",
            "2.898070812225342 41.8358154296875\n",
            "2.848832368850708 30.25644302368164\n",
            "0.142157644033432 79.57372283935547\n",
            "-0.387076735496521 18.059070587158203\n",
            "4.9491286277771 -105.36885070800781\n",
            "4.808138847351074 -111.4444351196289\n",
            "5.859455585479736 -39.298431396484375\n",
            "3.2254843711853027 -226.52633666992188\n",
            "-0.15304134786128998 -24.010086059570312\n",
            "-0.24056287109851837 -322.233642578125\n",
            "4.99470329284668 -219.46011352539062\n",
            "8.548730850219727 -153.39608764648438\n",
            "7.779422760009766 77.33183288574219\n",
            "10.325225830078125 512.3668823242188\n",
            "-51.266963958740234 1510.92138671875\n",
            "-42.648536682128906 1799.49951171875\n",
            "-28.911090850830078 2276.670654296875\n",
            "-21.382957458496094 1903.7607421875\n",
            "1.8315070867538452 2791.792724609375\n",
            "-2.1968159675598145 2569.84228515625\n",
            "-10.699722290039062 2867.38671875\n",
            "-5.333602428436279 1915.5601806640625\n",
            "-10.783285140991211 2124.8525390625\n",
            "-10.648314476013184 2127.93603515625\n",
            "29.7602596282959 2889.9580078125\n",
            "7.899409294128418 1225.6927490234375\n",
            "9.045432090759277 1302.9556884765625\n",
            "-28.994136810302734 -2445.5927734375\n",
            "-90.09684753417969 -6251.1416015625\n",
            "-87.06941223144531 -6308.62890625\n",
            "48.30533218383789 -8928.619140625\n",
            "69.07599639892578 -9557.5830078125\n",
            "2.4385018348693848 -14496.1279296875\n",
            "-16.692123413085938 -16735.04296875\n",
            "45.565406799316406 -12795.328125\n",
            "-17.756656646728516 -15266.037109375\n",
            "-78.1708984375 -12309.109375\n",
            "-73.13980102539062 -12568.13671875\n",
            "-122.841064453125 -14602.6884765625\n",
            "-293.7530212402344 -19794.529296875\n",
            "-254.05816650390625 -17118.240234375\n",
            "125.37374877929688 -8161.572265625\n",
            "115.05756378173828 -14847.13671875\n",
            "114.93696594238281 -14726.9267578125\n",
            "119.73270416259766 -15067.849609375\n",
            "98.5572509765625 -13874.609375\n",
            "172.40322875976562 -16375.4970703125\n",
            "159.437255859375 -11674.00390625\n",
            "6.108360290527344 -6346.5048828125\n",
            "74.56302642822266 8362.5380859375\n",
            "22.953603744506836 1530.66552734375\n",
            "114.03326416015625 8481.74609375\n",
            "158.11788940429688 9937.833984375\n",
            "-386.6989440917969 -10300.634765625\n",
            "-268.822998046875 -21397.509765625\n",
            "-233.54994201660156 -15204.310546875\n",
            "271.8629455566406 -31380.767578125\n",
            "206.80894470214844 -46665.87109375\n",
            "1560.3614501953125 -71320.171875\n",
            "2052.1396484375 -55684.578125\n",
            "1769.9012451171875 -64486.63671875\n",
            "1865.6590576171875 -43693.20703125\n",
            "2032.7882080078125 -23987.30078125\n",
            "2038.7823486328125 -32294.84765625\n",
            "4042.3955078125 3496.375\n",
            "3969.10986328125 9733.7548828125\n",
            "3640.976806640625 22335.5234375\n",
            "3774.9345703125 48051.0390625\n",
            "2238.97509765625 12513.24609375\n",
            "4329.21435546875 61447.59375\n",
            "4858.84130859375 49660.859375\n",
            "6192.658203125 9671.73046875\n",
            "6604.77490234375 227381.890625\n",
            "6351.25 223473.75\n",
            "16032.5732421875 364250.21875\n",
            "17402.72265625 456630.34375\n",
            "9974.09375 617163.375\n",
            "9635.0224609375 831739.375\n",
            "1822.6895751953125 602299.0625\n",
            "2153.82421875 692319.875\n",
            "3698.806396484375 816827.625\n",
            "-366.4542541503906 635688.75\n",
            "-13196.9189453125 1014073.375\n",
            "-12397.228515625 1082771.125\n",
            "-12353.7265625 1096941.75\n",
            "-12123.7763671875 1109290.375\n",
            "-11044.34765625 871658.375\n",
            "20430.427734375 1623696.75\n",
            "26795.6484375 1775169.875\n",
            "20839.20703125 1104412.875\n",
            "7085.3740234375 291797.6875\n",
            "32440.96875 1451410.0\n",
            "-6921.1962890625 275545.625\n",
            "84562.40625 -1120359.0\n",
            "114264.5390625 47697.5\n",
            "256062.375 -3360565.25\n",
            "243897.609375 -780737.0\n",
            "176947.015625 2146669.0\n",
            "81612.5625 -6595509.0\n",
            "86893.4453125 -5232055.0\n",
            "-377957.0625 -16671338.0\n",
            "-337786.875 -20468414.0\n",
            "-302931.21875 -31289804.0\n",
            "-362949.75 -29391996.0\n",
            "-368190.34375 -29455496.0\n",
            "-512495.53125 -31042602.0\n",
            "-367465.15625 -35073792.0\n",
            "-398591.875 -36120732.0\n",
            "-1146493.75 -56884948.0\n",
            "-1057345.375 -54102524.0\n",
            "-967585.9375 -43657216.0\n",
            "-630769.8125 -59341332.0\n",
            "-1043018.5 -68752800.0\n",
            "-1689340.75 -112155856.0\n",
            "-1714504.25 -150799648.0\n",
            "-1651037.875 -178762832.0\n",
            "-1135157.875 -80028392.0\n",
            "-928252.9375 -89369552.0\n",
            "714758.625 -140337216.0\n",
            "-2006746.5 -189921216.0\n",
            "-4946544.0 -69234336.0\n",
            "3069070.0 146617472.0\n",
            "-7509009.5 521576896.0\n",
            "-8689633.0 600688320.0\n",
            "-15547357.0 245452192.0\n",
            "-13115574.0 417232352.0\n",
            "-12742373.0 355676896.0\n",
            "-9110197.0 461682336.0\n",
            "-9208194.0 714970496.0\n",
            "-8477465.0 625272704.0\n",
            "-9191641.0 399685824.0\n",
            "-11098169.0 315750528.0\n",
            "-12738656.0 -142132320.0\n",
            "-7750778.0 -15006160.0\n",
            "-24846590.0 -382036864.0\n",
            "-27873668.0 -1353877760.0\n",
            "-48111824.0 -2082300032.0\n",
            "-37415700.0 -3302013952.0\n",
            "-22987744.0 -4028381440.0\n",
            "-19907614.0 -4504914944.0\n",
            "-39541060.0 -3050827776.0\n",
            "-32589498.0 -2494015488.0\n",
            "-98650464.0 -5088192512.0\n",
            "-122770016.0 -8550548480.0\n",
            "-125504264.0 -4639999488.0\n",
            "-221954080.0 -2736039936.0\n",
            "-317743104.0 -9658642432.0\n",
            "-294868352.0 -7508642816.0\n",
            "-315596064.0 -6113042432.0\n",
            "-362475680.0 -2626071296.0\n",
            "80029424.0 -11171770368.0\n",
            "352721.90625 1975455744.0\n",
            "79454360.0 18340354048.0\n",
            "-224013712.0 2920776704.0\n",
            "265796624.0 -9397566464.0\n",
            "206346144.0 -17324003328.0\n",
            "143717728.0 -19631118336.0\n",
            "239331984.0 -23105085440.0\n",
            "952926912.0 -41771569152.0\n",
            "901700416.0 -37404024832.0\n",
            "1311150720.0 -60284932096.0\n",
            "2287768576.0 -31415947264.0\n",
            "2162547712.0 -23369306112.0\n",
            "2054896896.0 -15545503744.0\n",
            "2066109952.0 -5199798272.0\n",
            "2138535680.0 -3375112704.0\n",
            "1109841920.0 -26632087552.0\n",
            "1058775040.0 -28286574592.0\n",
            "1720418560.0 -47601446912.0\n",
            "1862370560.0 -37637668864.0\n",
            "1857912960.0 -52725616640.0\n",
            "2991494656.0 -71612006400.0\n",
            "2611315456.0 -83548856320.0\n",
            "CPU times: user 181 ms, sys: 29.1 ms, total: 210 ms\n",
            "Wall time: 192 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqGpBujPhhQ",
        "colab_type": "code",
        "outputId": "1190f858-7f67-42f7-8bfa-72c47c21f9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "learning_rate = 0.001\n",
        "N = 1000000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True)\n",
        "b = torch.ones([1], requires_grad=True)\n",
        "\n",
        "print(torch.mean(w).item(), b.item())\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  x = torch.randn([N])\n",
        "  y = torch.dot(3*torch.ones([N]), x) - 2\n",
        "  \n",
        "  y_hat = torch.dot(w, x) + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(torch.mean(w).item(), b.item())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5005515813827515 1.0\n",
            "0.5006411671638489 1.7451366186141968\n",
            "0.5009893178939819 0.033278703689575195\n",
            "0.5011156797409058 -0.49509280920028687\n",
            "0.5021746158599854 3.9337382316589355\n",
            "0.5043640732765198 0.33821773529052734\n",
            "0.5094436407089233 -8.63611125946045\n",
            "0.502781331539154 -50.512115478515625\n",
            "0.6924042701721191 -183.3279571533203\n",
            "1.3362212181091309 -637.0899047851562\n",
            "2.1953375339508057 235.3001708984375\n",
            "-0.22361615300178528 -1779.9315185546875\n",
            "-0.31165921688079834 -2466.015380859375\n",
            "-0.2942468225955963 1070.5849609375\n",
            "1.093262791633606 -3399.56494140625\n",
            "0.3899768888950348 509.388916015625\n",
            "10.90703010559082 6531.3837890625\n",
            "19.239044189453125 -6258.56640625\n",
            "16.307079315185547 3015.0390625\n",
            "23.90019989013672 13971.861328125\n",
            "21.4930477142334 28961.21875\n",
            "28.341707229614258 76811.578125\n",
            "32.91560745239258 -29101.765625\n",
            "37.92844772338867 -53287.3359375\n",
            "392.80010986328125 468729.40625\n",
            "-386.80780029296875 -1031041.375\n",
            "-1325.7750244140625 -1744273.375\n",
            "-2412.51123046875 -2814413.5\n",
            "-3603.55078125 -2142308.75\n",
            "4273.10546875 -7898430.0\n",
            "4330.43505859375 -8598835.0\n",
            "4542.14404296875 -8353149.0\n",
            "11488.4853515625 -12199067.0\n",
            "11498.271484375 -12598889.0\n",
            "16021.2353515625 -31777412.0\n",
            "45491.02734375 -63250040.0\n",
            "82340.265625 27233272.0\n",
            "398861.75 -136082816.0\n",
            "370759.4375 -500483488.0\n",
            "344434.21875 -2457536256.0\n",
            "1989159.125 -3891929600.0\n",
            "1768706.25 -8392328192.0\n",
            "32130786.0 6111559680.0\n",
            "22563238.0 22795073536.0\n",
            "22963084.0 82302312448.0\n",
            "-19052402.0 -22682468352.0\n",
            "-275191936.0 248088723456.0\n",
            "-206445664.0 478125228032.0\n",
            "-186732832.0 -760988172288.0\n",
            "521451040.0 -5682596675584.0\n",
            "11681254400.0 -25900636700672.0\n",
            "11284805632.0 -22171189510144.0\n",
            "-2232717824.0 -11613346201600.0\n",
            "18920335360.0 25619234553856.0\n",
            "111029559296.0 -29300164132864.0\n",
            "61094424576.0 7978692378624.0\n",
            "-62725353472.0 -70253660864512.0\n",
            "-25198022656.0 -192124893003776.0\n",
            "-36449112064.0 -175152406986752.0\n",
            "-42037035008.0 -207327449841664.0\n",
            "73306906624.0 -306066751488000.0\n",
            "-117799452672.0 -522797143031808.0\n",
            "-237644365824.0 -413665211711488.0\n",
            "-531435192320.0 -751854694694912.0\n",
            "-701537845248.0 -623354507689984.0\n",
            "-398606532608.0 -154929738022912.0\n",
            "-660253704192.0 -863302519357440.0\n",
            "637527785472.0 -3120371049955328.0\n",
            "825510395904.0 -2970680702271488.0\n",
            "-2254752186368.0 -651576603574272.0\n",
            "-1936121397248.0 237642687971328.0\n",
            "-2041463832576.0 92806475415552.0\n",
            "-2699446452224.0 5818908665708544.0\n",
            "-2055521042432.0 1.344565281816576e+16\n",
            "-3926084812800.0 2.275431582741299e+16\n",
            "35840902299648.0 453331650609152.0\n",
            "60986400702464.0 5.722275122774016e+16\n",
            "81828060856320.0 6.670186860406374e+16\n",
            "88613765251072.0 9.407085620808909e+16\n",
            "103990335373312.0 1.2529050962624512e+17\n",
            "-13804447465472.0 -9.150816948165018e+16\n",
            "-248679243972608.0 -1.0406399269341757e+18\n",
            "1425650372050944.0 -2.5144126684214067e+17\n",
            "4275156759347200.0 2.163029368027218e+18\n",
            "4826809875038208.0 3.6439404138798776e+18\n",
            "8194787937091584.0 -2.099664787796394e+18\n",
            "1.6507802365198336e+16 -9.319861878773514e+18\n",
            "9282733217939456.0 -1.790060345405368e+19\n",
            "781001886269440.0 -1.5540057542334874e+18\n",
            "6929312330547200.0 -1.687659419024543e+19\n",
            "-3.266667084985139e+16 5.869609783975215e+18\n",
            "-4.183348397421363e+16 1.0688150223470985e+20\n",
            "7066107038924800.0 1.8393543543892633e+20\n",
            "8.154642233530778e+16 4.180678164026638e+20\n",
            "1.2548479247187968e+16 2.8650676413182404e+20\n",
            "1.093910715544109e+18 -1.0998623455969815e+21\n",
            "1.227221277731717e+18 -1.0355665647793382e+21\n",
            "1.0271139410477056e+18 -5.863535422036404e+20\n",
            "1.6089641557531034e+18 4.952790906004243e+21\n",
            "-3.5645538189285786e+17 -4.5257517080376246e+20\n",
            "2.6994160551063454e+19 -1.8864135435374436e+22\n",
            "2.810367113758245e+18 -4.42158097167675e+22\n",
            "4.493296323808933e+19 -6.462066486526221e+21\n",
            "3.866795917716121e+19 -5.599796493230761e+22\n",
            "-3.3908767076797907e+19 2.4781966676730883e+22\n",
            "-3.7636388571888746e+20 -1.5815543013016104e+23\n",
            "-1.7435951599374146e+20 3.0535108035113833e+22\n",
            "-3.11813721891042e+20 1.2789369959962785e+23\n",
            "-2.2115026245663274e+20 5.5814808039062076e+22\n",
            "1.0237643190058604e+21 -1.0250543672378214e+24\n",
            "2.6200869508692836e+20 -5.341675562891782e+24\n",
            "2.6023146208397728e+20 -5.168911428347951e+24\n",
            "-3.201115549463512e+21 -1.371363236241697e+25\n",
            "-5.999831094521749e+21 -1.752573734144039e+25\n",
            "-1.0006602055250034e+22 1.326399066977729e+25\n",
            "-1.1460213144377713e+22 -2.246330354067393e+25\n",
            "-8.651497750411866e+22 6.958856190726617e+25\n",
            "3.117135857607023e+23 3.0117818271053663e+26\n",
            "1.5599343209304556e+23 6.294851064865624e+26\n",
            "-4.179679575251761e+22 -4.282677269826334e+26\n",
            "6.895346817892446e+23 -1.7218549523105288e+27\n",
            "7.794242245085505e+23 -9.210347897668974e+26\n",
            "2.022521340483034e+24 3.6874871693299916e+26\n",
            "-1.9346522927005515e+24 -1.1448184402310767e+27\n",
            "-2.54022042188522e+24 -9.911161103252325e+27\n",
            "-3.3775558935701723e+24 -7.438090832738872e+27\n",
            "-5.470999344524284e+24 -1.4278084505689338e+28\n",
            "-1.5661870249782245e+25 -3.690041113668299e+28\n",
            "-7.73853273210645e+25 -1.248031925353932e+29\n",
            "1.3305234130761592e+25 2.8262041137359623e+28\n",
            "3.29659665024125e+25 5.638954205362229e+28\n",
            "-2.8968257302048444e+25 2.353695079350266e+29\n",
            "-6.879694294377302e+25 -1.2917002149050056e+29\n",
            "1.8668112381291696e+26 2.19352827540271e+29\n",
            "-5.557423378138968e+25 -1.5186137023000783e+29\n",
            "5.5851220867028465e+25 -5.8545326909357994e+29\n",
            "-7.038632824822189e+25 1.0882354304964968e+30\n",
            "1.1013445557507077e+27 3.158841866391657e+30\n",
            "-4.221153984139603e+27 1.212929298358865e+31\n",
            "-2.421868011922939e+28 -9.226328427167712e+30\n",
            "-5.822051687582644e+28 1.4750314278210704e+31\n",
            "-1.4994733842610297e+29 6.642469995810939e+31\n",
            "-1.0215239003450785e+29 3.1505163932174915e+32\n",
            "9.072886273091762e+29 -3.2237293277096157e+32\n",
            "2.8111551029019445e+30 -1.8340100251113498e+33\n",
            "1.7036188694638452e+30 -1.0833018308230175e+33\n",
            "8.121925578338326e+29 -2.8819344697191845e+32\n",
            "9.396414467465205e+29 -2.0581499011993117e+33\n",
            "-3.296228427773032e+30 -4.998419664647236e+33\n",
            "5.270209956378218e+30 -1.8977146671209833e+34\n",
            "9.341574721088664e+30 -1.5445592179157797e+33\n",
            "8.140282663561992e+31 -4.508462742241709e+34\n",
            "8.975000486395076e+31 -5.314891546153306e+34\n",
            "2.9998297377175604e+31 2.0495681913619756e+33\n",
            "nan 1.5556677490643031e+35\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "nan nan\n",
            "CPU times: user 2.53 s, sys: 51.1 ms, total: 2.58 s\n",
            "Wall time: 2.58 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6_yirsZReO9",
        "colab_type": "code",
        "outputId": "61ea8ab5-fe91-4882-b0e4-8148fafb8f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "learning_rate = 0.01\n",
        "N = 1000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True, device=cuda0)\n",
        "b = torch.ones([1], requires_grad=True, device=cuda0)\n",
        "\n",
        "print(torch.mean(w).item(), b.item())\n",
        "\n",
        "for i in range(epochs):\n",
        "  x = torch.randn([N], device=cuda0)\n",
        "  y = torch.dot(3*torch.ones([N], device=cuda0), x) - 2\n",
        "\n",
        "  y_hat = torch.dot(w, x) + b\n",
        "\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  # print(loss)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(torch.mean(w).item(), b.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5132827162742615 1.0\n",
            "0.5313652753829956 1.9489386081695557\n",
            "0.5992146134376526 -0.17768144607543945\n",
            "0.5984985828399658 -0.30758029222488403\n",
            "0.598190426826477 -0.449088990688324\n",
            "0.6057395935058594 0.8265195488929749\n",
            "0.6344659328460693 3.3439412117004395\n",
            "0.6466487646102905 3.579383373260498\n",
            "0.9510200023651123 -1.2470111846923828\n",
            "0.8970737457275391 -2.700594663619995\n",
            "0.7667921185493469 1.505833387374878\n",
            "0.7016636729240417 -2.0993030071258545\n",
            "0.5110252499580383 -10.808579444885254\n",
            "0.5442276000976562 -14.383378982543945\n",
            "0.6028478741645813 -8.716846466064453\n",
            "0.7213584184646606 0.07077312469482422\n",
            "0.7276046872138977 -1.0910871028900146\n",
            "0.6784216165542603 -6.633345603942871\n",
            "0.6972595453262329 -5.215209484100342\n",
            "0.7004274725914001 -2.855556011199951\n",
            "0.5644440054893494 -5.868660926818848\n",
            "0.6005802154541016 8.732505798339844\n",
            "0.5059733986854553 6.295694351196289\n",
            "1.0930827856063843 -17.172513961791992\n",
            "0.9921697378158569 -38.546295166015625\n",
            "0.5140179395675659 -28.59299087524414\n",
            "0.3180336356163025 -22.800416946411133\n",
            "0.9346951842308044 12.19428825378418\n",
            "0.9220120906829834 -14.2100830078125\n",
            "2.6731979846954346 -56.624568939208984\n",
            "4.851397514343262 -21.30931854248047\n",
            "4.794416427612305 -26.351436614990234\n",
            "3.892476797103882 -65.14181518554688\n",
            "3.429311752319336 -99.85260009765625\n",
            "3.841171979904175 -34.149452209472656\n",
            "11.938185691833496 -233.25537109375\n",
            "12.872941970825195 -276.31732177734375\n",
            "12.70980167388916 -311.9195251464844\n",
            "13.982717514038086 -713.3231201171875\n",
            "14.9540376663208 -744.2911987304688\n",
            "14.87481689453125 -741.1685791015625\n",
            "14.969985961914062 -722.848876953125\n",
            "17.456167221069336 -1215.58935546875\n",
            "14.293782234191895 -1081.9239501953125\n",
            "15.340107917785645 -949.080322265625\n",
            "8.894552230834961 -701.6090698242188\n",
            "-1.0455166101455688 -1041.1573486328125\n",
            "-14.671137809753418 -546.5708618164062\n",
            "35.633235931396484 409.80926513671875\n",
            "23.979934692382812 1084.8909912109375\n",
            "23.431161880493164 1046.23291015625\n",
            "22.04283905029297 913.2816162109375\n",
            "-22.97138786315918 1631.90771484375\n",
            "-20.31586456298828 1537.7342529296875\n",
            "29.669614791870117 210.1064453125\n",
            "29.547061920166016 405.47943115234375\n",
            "-26.170185089111328 3064.733154296875\n",
            "164.4342803955078 7666.46875\n",
            "170.56155395507812 5139.8115234375\n",
            "251.6020050048828 6759.66748046875\n",
            "238.789794921875 4724.41943359375\n",
            "254.0363311767578 1736.312255859375\n",
            "300.76873779296875 684.3853759765625\n",
            "396.3018798828125 4765.03271484375\n",
            "529.730224609375 -1334.5556640625\n",
            "444.6637878417969 3028.822265625\n",
            "276.4186096191406 10031.044921875\n",
            "253.61920166015625 16543.8046875\n",
            "431.5460205078125 28439.10546875\n",
            "147.89511108398438 21605.708984375\n",
            "135.65721130371094 22048.306640625\n",
            "-257.1324157714844 8128.6455078125\n",
            "-497.5938415527344 14680.634765625\n",
            "-416.14337158203125 19923.078125\n",
            "675.6403198242188 4365.9208984375\n",
            "555.5922241210938 9447.306640625\n",
            "333.1230163574219 2783.75244140625\n",
            "-1410.603759765625 24742.787109375\n",
            "-1709.423828125 1944.830078125\n",
            "-2898.335205078125 26585.802734375\n",
            "-2864.669921875 -32639.501953125\n",
            "-2820.351318359375 -34163.34765625\n",
            "-1946.82080078125 -53530.53125\n",
            "-2035.7164306640625 -36877.15625\n",
            "-3609.728515625 -98413.5703125\n",
            "-4772.81396484375 -43340.35546875\n",
            "-12326.5908203125 76098.109375\n",
            "-13619.6904296875 124237.6875\n",
            "-6585.1083984375 217389.59375\n",
            "-7848.75 133702.046875\n",
            "-7970.6142578125 149444.109375\n",
            "-6385.20068359375 248872.6875\n",
            "-19128.15234375 -42797.9375\n",
            "-16417.138671875 -323503.5\n",
            "-24689.634765625 -786238.0\n",
            "-24749.6015625 -712900.1875\n",
            "-31955.521484375 -210755.15625\n",
            "-17063.876953125 157331.75\n",
            "-14455.70703125 733955.875\n",
            "-20345.353515625 500284.625\n",
            "-19568.453125 554022.625\n",
            "-32686.29296875 960010.375\n",
            "-35706.50390625 507343.9375\n",
            "-17380.80078125 55357.0\n",
            "-65582.171875 -719789.625\n",
            "-104700.671875 -1317048.75\n",
            "-101602.828125 42313.0\n",
            "10618.6748046875 -2658710.5\n",
            "10983.130859375 -3305772.25\n",
            "1808.9180908203125 -3450566.75\n",
            "10835.5849609375 -7532927.0\n",
            "11679.544921875 -7388068.0\n",
            "33984.953125 -9525184.0\n",
            "57635.5859375 -4063122.5\n",
            "-69348.5625 -8327558.0\n",
            "-287161.625 -12450970.0\n",
            "-192985.890625 -19970390.0\n",
            "-184703.578125 -19629510.0\n",
            "6030.49609375 -14817046.0\n",
            "5140.984375 -14311355.0\n",
            "126037.0 -11024654.0\n",
            "-125220.8359375 -25246780.0\n",
            "-267078.875 -8475321.0\n",
            "-625475.25 -20442222.0\n",
            "-986911.4375 -7163294.0\n",
            "-806665.8125 23701722.0\n",
            "-2477224.0 77080264.0\n",
            "-2495639.0 68831768.0\n",
            "-3592451.5 134139464.0\n",
            "-3699608.25 151258752.0\n",
            "-5879294.0 256623712.0\n",
            "-6389204.5 288529792.0\n",
            "-8679695.0 169115744.0\n",
            "-6286870.5 281290176.0\n",
            "-6427701.5 382354048.0\n",
            "-8057128.0 621904640.0\n",
            "-8040178.0 744219136.0\n",
            "-11948287.0 659028352.0\n",
            "-16741017.0 718928896.0\n",
            "-15022595.0 811420416.0\n",
            "-6501238.5 598439808.0\n",
            "-8586978.0 743322240.0\n",
            "-10048492.0 581574272.0\n",
            "-12852034.0 377022720.0\n",
            "-9464144.0 735102976.0\n",
            "-8016366.0 680625152.0\n",
            "-13192088.0 587685312.0\n",
            "-17086906.0 381528832.0\n",
            "-15905512.0 426732992.0\n",
            "11469809.0 804046080.0\n",
            "-53081728.0 -51634176.0\n",
            "-21832402.0 606509312.0\n",
            "-33538688.0 1249301376.0\n",
            "-30555162.0 1113935872.0\n",
            "-1367840.875 205231168.0\n",
            "-79228768.0 -1933307648.0\n",
            "-80539944.0 -2388006656.0\n",
            "-260223936.0 -4878179328.0\n",
            "-286322272.0 -7752139264.0\n",
            "-270339776.0 -8229832704.0\n",
            "-120387048.0 -11479054336.0\n",
            "-158237664.0 -10556081152.0\n",
            "-212617312.0 -6355959808.0\n",
            "-217333840.0 -6484868096.0\n",
            "-58717136.0 -9887460352.0\n",
            "-51073836.0 -13388812288.0\n",
            "-328015872.0 -6770544640.0\n",
            "-589760768.0 -12826940416.0\n",
            "-872964864.0 -20977262592.0\n",
            "-1483378944.0 -31139584000.0\n",
            "-78163384.0 -4742189056.0\n",
            "-483635968.0 -30554552320.0\n",
            "-648819648.0 -19914129408.0\n",
            "2710594816.0 -63452143616.0\n",
            "2511825152.0 -35092922368.0\n",
            "1229930880.0 4893728768.0\n",
            "1267189248.0 19074275328.0\n",
            "2153626112.0 -15143864320.0\n",
            "444961472.0 -61042966528.0\n",
            "314953856.0 -69008523264.0\n",
            "700683520.0 -84892000256.0\n",
            "-2526268928.0 -5974474752.0\n",
            "-2628029952.0 98353086464.0\n",
            "-11188512768.0 -56142495744.0\n",
            "-11093646336.0 -7552016384.0\n",
            "-5940600832.0 -156941025280.0\n",
            "-568102400.0 -254257332224.0\n",
            "-4662411264.0 -176893067264.0\n",
            "-3317158912.0 -445838589952.0\n",
            "17326133248.0 -149223735296.0\n",
            "-11690455040.0 -692769128448.0\n",
            "-26895648768.0 -997825970176.0\n",
            "-36181426176.0 -729370263552.0\n",
            "-26203869184.0 -1020474818560.0\n",
            "-5151134208.0 -435916505088.0\n",
            "20992184320.0 307617202176.0\n",
            "21604247552.0 633918128128.0\n",
            "19881945088.0 1103443918848.0\n",
            "23844610048.0 915131662336.0\n",
            "42067251200.0 3627321393152.0\n",
            "38613938176.0 2660748230656.0\n",
            "CPU times: user 290 ms, sys: 46.2 ms, total: 336 ms\n",
            "Wall time: 306 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk68m8eQR20b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}